# ğŸ§  Agent with Streaming Responses using OpenAI SDK & Chainlit

## ğŸš€ Overview

This project implements an **agent-based conversational system** that supports **real-time streaming responses (token-by-token generation)**.

It uses:

- **Chainlit** for interactive front-end  
- **OpenAI SDK (Async)** for calling LLMs with streaming outputs  
- **Agentic AI structure** to handle **chat history, instructions, and memory**  

---

## ğŸ› ï¸ Features

- âœ… **Token Streaming** for fast, real-time responses  
- âœ… **Agent-based context management**  
- âœ… **Chainlit interactive chat interface**  
- âœ… **LLM agnostic**: Supports OpenAI, Gemini (via OpenAI-compatible proxy), Claude, etc.

---

## ğŸ“¦ Tech Stack

- **Python**  
- **Chainlit**  
- **OpenAI SDK (AsyncOpenAI)**  
- **Agentic AI Framework (custom agents + runner)**  
- **Dotenv for environment configs**

---

## ğŸ”§ Setup

### 1ï¸âƒ£ Install dependencies:

```bash
pip install chainlit openai python-dotenv
